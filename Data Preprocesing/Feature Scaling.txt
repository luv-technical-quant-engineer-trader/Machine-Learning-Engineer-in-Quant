Feature scaling ensures that all features contribute equally to the model’s learning, especially for distance- and gradient-based algorithms.
This is done becuase features in a machine learning model can vary a lot. They can range from 0 to 1 or 100 to 1000 or 10k to 100k. Because of this the model thinks that the feature with the higher number can be of greater significance and this significance has a high chances of being wrong. So to bring all the features in one standard scale, feature scaling is done.
- This is not a necessity to apply feature scaling for all the machine learning models

- Feature scaling is always applied to columns not rows

- There are two types of feature scaling-
    - Normalization - Values are compressed between 0 and 1
    - Standardization - Value are compressed between -3 and 3 (outliers can be outside this boundaries)


!IMPORTANT -  The feature scaling should not be done using fit on the training data and transform in the test data. If we use fit_transform() directly on the test data, that is a serious data leakage issue.
Therefore we use the same scaler on the test set as the training set.
- Use fit_Transform on training data, that will initialize the scaler
- Use the same scaler on the test data using transform


- Normalization works best when we have normal distribution in our data.
- Standardization will work all the time.
- Do not apply dummy variable on dummy variables that are resulted from one hot encoding or label encoding


    | Aspect       | **Standardization**                          | **Normalization**                                     |
| ------------ | -------------------------------------------- | ----------------------------------------------------- |
| Formula      | $z = \frac{x - \mu}{\sigma}$                 | $x' = \frac{x - \text{min}}{\text{max} - \text{min}}$ |
| Output Range | Mean = 0, Std = 1 (not bounded)              | \[0, 1]                                               |
| Use Cases    | Linear models, SVM, PCA, Logistic Regression | Neural networks, k-NN, Min-max bounded input          |
| When to Use  | When features follow Gaussian distribution   | When features have different scales and bounds        |



Great question. Here's **why**:

---

### ✅ **Why Standardization (Z-score) is used for algorithms assuming normal distribution:**

* Algorithms like **Linear Regression**, **Logistic Regression**, **SVM**, and **PCA** assume or perform better when data is **centered around 0 with unit variance**.
* **Standardization** makes the data **mean = 0 and std = 1**, aligning with assumptions of many statistical models and improving convergence in gradient descent.
* It **preserves outliers** and does **not compress the range**, which is helpful when outliers are meaningful.

---

### ✅ **Why Normalization (Min-Max Scaling) is better for distance/gradient-based algorithms:**

* **k-NN, K-Means, and Neural Networks** rely heavily on **distance calculations** (like Euclidean distance) or **gradient updates**.
* Features on larger scales would **dominate** the distance or gradient if not scaled, skewing results.
* **Normalization bounds data to \[0, 1]**, making each feature contribute **equally** and helping in **faster, stable convergence**, especially in **Neural Networks** where activations like sigmoid/tanh expect bounded input.

---

### Summary:

| Scaling Type        | Why Use It                                                                                             |
| ------------------- | ------------------------------------------------------------------------------------------------------ |
| **Standardization** | Centers & scales data for models assuming normal distribution (e.g., SVM, PCA)                         |
| **Normalization**   | Makes all features equal in scale for distance-based models (e.g., k-NN) and gradient-friendly for NNs |
